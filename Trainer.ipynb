{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lLsS2s2MR-Q"
      },
      "source": [
        "Dataset\n",
        "\n",
        "Training \n",
        "  Positive : 26974, \n",
        "  Negative : 27470\n",
        "\n",
        "Validation \n",
        "  Positive : 2150, \n",
        "  Negative : 2136"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhXlyV5WGag2",
        "outputId": "874b88b9-643a-4480-d251-4230accbf026"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "# from tensorflow import feature_column\n",
        "from tensorflow.keras import layers\n",
        "# from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPYJ2yDsarsG",
        "outputId": "95820a8a-6e21-434d-f250-242e6dad91a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F_N6gqaa2ar",
        "outputId": "663bb859-6702-427c-883d-e231d0c4ccfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data-edit    training.txt\t Train_negative.txt   Train_positive.txt\n",
            "train1.csv   training.xlsx\t Train_negative.xlsx\n",
            "train1.xlsx  Train_negative.csv  Train_positive.csv\n"
          ]
        }
      ],
      "source": [
        "!ls '/content/drive/MyDrive/Colab Notebooks/2/training'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Kyc3PgjHbzP"
      },
      "outputs": [],
      "source": [
        "#utitliy functions \n",
        "\n",
        "import os\n",
        "import sys\n",
        "# os.environ['MKL_THREADING_LAYER'] = 'GNU'\n",
        "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "\n",
        "import datetime\n",
        "\n",
        "output_path=\"/content/drive/MyDrive/Colab Notebooks/2/results/TargetNet_training/\"\n",
        "\n",
        "def set_output(string):\n",
        "    \"\"\" set output configurations \"\"\"\n",
        "    output, save_prefix = sys.stdout, None\n",
        "    if output_path is not None:\n",
        "        save_prefix = output_path\n",
        "        if not os.path.exists(save_prefix):\n",
        "            os.makedirs(save_prefix, exist_ok=True)\n",
        "        output = open( output_path + string + \".txt\", \"a\")\n",
        "\n",
        "    return output, save_prefix\n",
        "\n",
        "def Print(string, output, newline=False, timestamp=True):\n",
        "    \"\"\" print to stdout and a file (if given) \"\"\"\n",
        "    if timestamp:\n",
        "        time = datetime.datetime.now()\n",
        "        line = '\\t'.join([str(time.strftime('%m-%d %H:%M:%S')), string])\n",
        "    else:\n",
        "        time = None\n",
        "        line = string\n",
        "\n",
        "    print(line, file=sys.stderr)\n",
        "    if newline: print(\"\", file=sys.stderr)\n",
        "\n",
        "    if not output == sys.stdout:\n",
        "        print(line, file=output)\n",
        "        if newline: print(\"\", file=output)\n",
        "\n",
        "    output.flush()\n",
        "    return time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPeuFd_sbDed",
        "outputId": "61fb1154-74de-4d34-ffe1-bbb351c984ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bio\n",
            "  Downloading bio-1.4.0-py3-none-any.whl (270 kB)\n",
            "\u001b[K     |████████████████████████████████| 270 kB 14.1 MB/s \n",
            "\u001b[?25hCollecting mygene\n",
            "  Downloading mygene-3.2.2-py2.py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from bio) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bio) (2.23.0)\n",
            "Collecting biopython>=1.79\n",
            "  Downloading biopython-1.79-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 57.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython>=1.79->bio) (1.21.6)\n",
            "Collecting biothings-client>=0.2.6\n",
            "  Downloading biothings_client-0.2.6-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bio) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bio) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bio) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bio) (3.0.4)\n",
            "Installing collected packages: biothings-client, mygene, biopython, bio\n",
            "Successfully installed bio-1.4.0 biopython-1.79 biothings-client-0.2.6 mygene-3.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install bio\n",
        "import sys\n",
        "import numpy as np\n",
        "from Bio import pairwise2\n",
        "\n",
        "# import torch\n",
        "\n",
        "#Loading the datasets\n",
        "Positive_Data = '/content/drive/MyDrive/Colab Notebooks/2/data/miRAW_positive.csv'\n",
        "Negative_Data = '/content/drive/MyDrive/Colab Notebooks/2/data/miRAW_negative.csv'\n",
        "TestingData = '/content/drive/MyDrive/Colab Notebooks/2/data/csv/Independent_dataset1.csv'\n",
        "\n",
        "class miRNA_CTS_dataset():\n",
        "    \"\"\" Pytorch dataloader for miRNA-CTS pair data \"\"\"\n",
        "    def __init__(self, X, labels, set_idxs, set_labels):\n",
        "        self.X = X\n",
        "        self.labels = labels\n",
        "        self.set_idxs = set_idxs\n",
        "        self.set_labels = set_labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.X[i], self.labels[i], self.set_idxs[i]\n",
        "\n",
        "def encode_RNA(mirna_seq, mirna_esa, cts_rev_seq, cts_rev_esa):\n",
        "    \"\"\" one-hot encoder for RNA sequences with/without extended seed alignments \"\"\"\n",
        "    chars = {\"A\":0, \"C\":1, \"G\":2, \"U\":3, \"-\":4}\n",
        "\n",
        "    x = np.zeros((64, 64), dtype=np.float32)\n",
        "    for i in range(len(mirna_esa)):\n",
        "      for j in range(5):\n",
        "        x[chars[mirna_esa[i]]+j, 5 + i] = 1\n",
        "    for i in range(10, len(mirna_seq)):\n",
        "      for j in range(5):\n",
        "        x[chars[mirna_seq[i]]+j, 5 + i - 10 + len(mirna_esa)] = 1\n",
        "    for i in range(5):\n",
        "      for j in range(5):\n",
        "        x[chars[cts_rev_seq[i]]+j + len(chars), i] = 1\n",
        "    for i in range(len(cts_rev_esa)):\n",
        "      for j in range(5):\n",
        "        x[chars[cts_rev_esa[i]]+j + len(chars), i + 5] = 1\n",
        "    for i in range(15, len(cts_rev_seq)):\n",
        "      for j in range(5):\n",
        "        x[chars[cts_rev_seq[i]]+j  + len(chars), i + 5 - 15 + len(cts_rev_esa)] = 1\n",
        "\n",
        "    return x\n",
        "        \n",
        "\n",
        "# def encode_RNA(mirna_seq, mirna_esa, cts_rev_seq, cts_rev_esa):\n",
        "#     \"\"\" one-hot encoder for RNA sequences with/without extended seed alignments \"\"\"\n",
        "#     chars = {\"A\":0, \"C\":1, \"G\":2, \"U\":3, \"-\":4}\n",
        " \n",
        "#     x = np.zeros((len(chars)* 2, 50), dtype=np.float32)\n",
        "#     for i in range(len(mirna_esa)):\n",
        "#         x[chars[mirna_esa[i]], 5 + i] = 1\n",
        "#     for i in range(10, len(mirna_seq)):\n",
        "#         x[chars[mirna_seq[i]], 5 + i - 10 + len(mirna_esa)] = 1\n",
        "#     for i in range(5):\n",
        "#         x[chars[cts_rev_seq[i]] + len(chars), i] = 1\n",
        "#     for i in range(len(cts_rev_esa)):\n",
        "#         x[chars[cts_rev_esa[i]] + len(chars), i + 5] = 1\n",
        "#     for i in range(15, len(cts_rev_seq)):\n",
        "#         x[chars[cts_rev_seq[i]]  + len(chars), i + 5 - 15 + len(cts_rev_esa)] = 1\n",
        "\n",
        "#     return x\n",
        "\n",
        "\n",
        "def reverse(seq):\n",
        "    \"\"\" reverse the given sequence \"\"\"\n",
        "    seq_r = \"\"\n",
        "    for i in range(len(seq)):\n",
        "        seq_r += seq[len(seq) - 1 - i]\n",
        "    return seq_r\n",
        "\n",
        "\n",
        "score_matrix = {}  # Allow watson-crick & wobble\n",
        "for c1 in 'ACGU':\n",
        "    for c2 in 'ACGU':\n",
        "        if (c1, c2) in [('A', 'U'), ('U', 'A'), ('G', 'C'), ('C', 'G')]:\n",
        "            score_matrix[(c1, c2)] = 1\n",
        "        elif (c1, c2) in [('U', 'G'), ('G', 'U')]:\n",
        "            score_matrix[(c1, c2)] = 1\n",
        "        else:\n",
        "            score_matrix[(c1, c2)] = 0\n",
        "\n",
        "\n",
        "def extended_seed_alignment(mi_seq, cts_r_seq):\n",
        "    \"\"\" extended seed alignment \"\"\"\n",
        "    alignment = pairwise2.align.globaldx(mi_seq[:10], cts_r_seq[5:15], score_matrix, one_alignment_only=True)[0]\n",
        "    mi_esa = alignment[0]\n",
        "    cts_r_esa = alignment[1]\n",
        "    esa_score = alignment[2]\n",
        "    return mi_esa, cts_r_esa, esa_score\n",
        "\n",
        "\n",
        "def get_dataset_from_configs(data_cfg,split_idx=None):\n",
        "  \n",
        "    FILE = open(data_cfg, \"r\")\n",
        "    lines = FILE.readlines()\n",
        "    FILE.close()\n",
        "\n",
        "    X, labels, set_idxs, set_labels = [], [], [], []\n",
        "    set_idx = 0\n",
        "    for l, line in enumerate(lines[1:]):\n",
        "      tokens = line.strip().split(\"\\t\")\n",
        "      print(tokens)\n",
        "      mirna_id, mirna_seq, mrna_id, mrna_seq = tokens[:4]\n",
        "      label = float(tokens[4]) if len(tokens) > 4 else 0\n",
        "      \n",
        "      mirna_seq = mirna_seq.upper().replace(\"T\", \"U\")\n",
        "      mrna_seq = mrna_seq.upper().replace(\"T\", \"U\")\n",
        "      mrna_rev_seq = reverse(mrna_seq)\n",
        "\n",
        "      for pos in range(len(mrna_rev_seq) - 40 + 1):\n",
        "          mirna_esa, cts_rev_esa, esa_score = extended_seed_alignment(mirna_seq, mrna_rev_seq[pos:pos+40])\n",
        "          if split_idx not in [\"train\", \"val\"] and esa_score < 6: continue\n",
        "\n",
        "          x = encode_RNA(mirna_seq, mirna_esa,mrna_rev_seq[pos:pos+40], cts_rev_esa).transpose()\n",
        "          # x = np.array(np.repeat(x[..., np.newaxis], 1, -3))\n",
        "          # print(x.shape)\n",
        "          X.append(np.array(x))\n",
        "          labels.append(tf.expand_dims(np.array(label), 0))\n",
        "          set_idxs.append(tf.expand_dims(np.array(set_idx), 0))\n",
        "\n",
        "      set_labels.append(label)\n",
        "      set_idx += 1\n",
        "\n",
        "      if set_idx % 5 == 0:\n",
        "          print('# {} {:.1%}'.format(split_idx, l / len(lines[1:])), end='\\r', file=sys.stderr)\n",
        "    print(' ' * 150, end='\\r', file=sys.stderr)\n",
        "\n",
        "    # print(len(set_labels))\n",
        "    # print((X[0]))\n",
        "    # print(len(labels))\n",
        "    X = np.array(X)\n",
        "    labels = np.array(labels)\n",
        "    dataset = miRNA_CTS_dataset(X, labels, set_idxs, np.array(set_labels))\n",
        "\n",
        "    return X, labels, set_idxs, set_labels\n",
        "\n",
        "output, save_prefix = set_output(\"train_model_log\")\n",
        "device = device_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTpOs_RhOnUj"
      },
      "outputs": [],
      "source": [
        "import random \n",
        "\n",
        "def shuffleData(X, y):\n",
        "    index = [i for i in range(len(X))]\n",
        "    random.shuffle(index)\n",
        "    X = X[index]\n",
        "    y = y[index]\n",
        "    return X, y;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnqCy_n0ObR9"
      },
      "outputs": [],
      "source": [
        "def chunkIt(seq, num):\n",
        "    avg = len(seq) / float(num)\n",
        "    out = []\n",
        "    last = 0.0\n",
        "\n",
        "    while last < len(seq):\n",
        "        out.append(seq[int(last):int(last + avg)])\n",
        "        last += avg\n",
        "    \n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOgBhodrJyO_",
        "outputId": "8dbda4b9-c2fd-4b35-c7b6-62592c4c4195"
      },
      "outputs": [],
      "source": [
        "start = Print(\" \".join(['start loading datasets']), output)\n",
        "\n",
        "Positive_X, Positive_y, Positive_set_idxs, Positive_set_labels = get_dataset_from_configs(Positive_Data,split_idx=\"train\")\n",
        "Negative_X, Negative_y, Negative_set_idxs, Negative_set_labels = get_dataset_from_configs(Negative_Data, split_idx=\"val\")\n",
        "\n",
        "# ind_X, ind_y, ind_set_idxs, ind_set_labels = get_dataset_from_configs(Negative_Data, split_idx=\"val\")\n",
        "\n",
        "print(len(Positive_X))\n",
        "print(len(Negative_X))\n",
        "\n",
        "folds = 10\n",
        "Positive_X_Slices = chunkIt(Positive_X, folds);\n",
        "Positive_y_Slices = chunkIt(Positive_y, folds);\n",
        "\n",
        "Negative_X_Slices = chunkIt(Negative_X, folds);\n",
        "Negative_y_Slices = chunkIt(Negative_y, folds);\n",
        "\n",
        "print(len(Positive_X_Slices), 'train examples')\n",
        "print(len(Positive_y_Slices), 'validation examples')\n",
        "print(len(Negative_X_Slices), 'test examples')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-Q2UJqocjyJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# for test_index in range(folds):\n",
        "#   test_X = np.concatenate((Positive_X_Slices[test_index],Negative_X_Slices[test_index]))\n",
        "#   test_y = np.concatenate((Positive_y_Slices[test_index],Negative_y_Slices[test_index]))\n",
        "\n",
        "#   validation_index = (test_index+1) % folds;\n",
        "\n",
        "#   valid_X = np.concatenate((Positive_X_Slices[validation_index],Negative_X_Slices[validation_index]))\n",
        "#   valid_y = np.concatenate((Positive_y_Slices[validation_index],Negative_y_Slices[validation_index]))\n",
        "\n",
        "#   start = 0;\n",
        "\n",
        "#   for val in range(0, folds):\n",
        "#     if val != test_index and val != validation_index:\n",
        "#       start = val;\n",
        "#       break;\n",
        "\n",
        "#   train_X = np.concatenate((Positive_X_Slices[start],Negative_X_Slices[start]))\n",
        "#   train_y = np.concatenate((Positive_y_Slices[start],Negative_y_Slices[start]))\n",
        "\n",
        "#   for i in range(0, folds):\n",
        "#     if i != test_index and i != validation_index and i != start:\n",
        "#       tempX = np.concatenate((Positive_X_Slices[i],Negative_X_Slices[i]))\n",
        "#       tempy = np.concatenate((Positive_y_Slices[i],Negative_y_Slices[i]))\n",
        "\n",
        "#       train_X = np.concatenate((train_X, tempX))\n",
        "#       train_y = np.concatenate((train_y, tempy))\n",
        "\n",
        "#   test_X, test_y = shuffleData(test_X,test_y);\n",
        "#   valid_X,valid_y = shuffleData(valid_X,valid_y);\n",
        "#   train_X,train_y = shuffleData(train_X,train_y);\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vl0DrpX3ztst"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from keras import optimizers\n",
        "from tensorflow import keras\n",
        "\n",
        "drop_out = 0.3\n",
        "LR= 0.001\n",
        "\n",
        "def getModel(batch, lr, dout):\n",
        "        model = Sequential()\n",
        "        model.add(Conv1D(input_shape=(64, 64),filters=320,kernel_size=ksize,padding=\"same\", activation=\"relu\"))\n",
        "        model.add(Conv1D(filters=320, kernel_size=ksize, activation='relu'))\n",
        "        model.add(MaxPool1D(pool_size=2))\n",
        "        # model.add(Conv1D(filters=320, kernel_size=ksize, activation='relu'))\n",
        "        # model.add(MaxPool1D(pool_size=2))\n",
        "        model.add(Dropout(dout))\n",
        "        model.add(Bidirectional(LSTM(32, activation='relu')))\n",
        "        model.add(Dropout(dout))\n",
        "        model.add(Dense(16, activation='relu'))\n",
        "        model.add(Dropout(dout))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        model.summary()\n",
        "        adam = keras.optimizers.Adam(lr)\n",
        "        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "        \n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0caNxe4Pei_u"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix,recall_score,matthews_corrcoef,roc_curve,roc_auc_score,auc\n",
        "#from tensorflow.compat.v1 import Session\n",
        "from tensorflow.keras import losses\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "def calculateScore(X, y, model):\n",
        "    \n",
        "    score = model.evaluate(X,y)\n",
        "    pred_y = model.predict(X)\n",
        "\n",
        "    accuracy = score[1];\n",
        "\n",
        "    tempLabel = np.zeros(shape = y.shape, dtype=np.int32)\n",
        "\n",
        "    for i in range(len(y)):\n",
        "        if pred_y[i] < 0.5:\n",
        "            tempLabel[i] = 0;\n",
        "        else:\n",
        "            tempLabel[i] = 1;\n",
        "    confusion = confusion_matrix(y, tempLabel)\n",
        "    TN, FP, FN, TP = confusion.ravel()\n",
        "\n",
        "    sensitivity = recall_score(y, tempLabel)\n",
        "    specificity = TN / float(TN+FP)\n",
        "    MCC = matthews_corrcoef(y, tempLabel)\n",
        "\n",
        "    F1Score = (2 * TP) / float(2 * TP + FP + FN)\n",
        "    precision = TP / float(TP + FP)\n",
        "\n",
        "    pred_y = pred_y.reshape((-1, ))\n",
        "\n",
        "    ROCArea = roc_auc_score(y, pred_y)\n",
        "    fpr, tpr, thresholds = roc_curve(y, pred_y)\n",
        "    lossValue = None;\n",
        "\n",
        "    print(y.shape)\n",
        "    print(pred_y.shape)\n",
        "\n",
        "    y_true = tf.convert_to_tensor(y, np.float32)\n",
        "    y_pred = tf.convert_to_tensor(pred_y, np.float32)\n",
        "\n",
        "    with tf.compat.v1.Session():\n",
        "        lossValue = losses.binary_crossentropy(y_true, y_pred).eval()\n",
        "\n",
        "    return {'sn' : sensitivity, 'sp' : specificity, 'acc' : accuracy, 'MCC' : MCC, 'AUC' : ROCArea, 'precision' : precision, 'F1' : F1Score, 'fpr' : fpr, 'tpr' : tpr, 'thresholds' : thresholds, 'lossValue' : lossValue}\n",
        "    # return {'sn' : sensitivity, 'sp' : specificity, 'acc' : accuracy, 'MCC' : MCC, 'AUC' : ROCArea, 'precision' : precision, 'F1' : F1Score, 'lossValue' : lossValue}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWIle5t2foDu"
      },
      "outputs": [],
      "source": [
        "from scipy import interp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def analyze(temp, OutputDir):\n",
        "\n",
        "    # temp = None\n",
        "    # with open(dataFile, 'rb') as file:\n",
        "    #        temp = pickle.load(file)\n",
        "\n",
        "    trainning_result, validation_result = temp;\n",
        "\n",
        "    file = open(OutputDir + '/performance.txt', 'w')\n",
        "\n",
        "    index = 0\n",
        "    for x in [trainning_result, validation_result]:\n",
        "\n",
        "\n",
        "        title = ''\n",
        "\n",
        "        if index == 0:\n",
        "            title = 'training_'\n",
        "        if index == 1:\n",
        "            title = 'validation_'\n",
        "\n",
        "        index += 1;\n",
        "\n",
        "        file.write(title +  'results\\n')\n",
        "\n",
        "\n",
        "        for j in ['sn', 'sp', 'acc', 'MCC', 'AUC', 'precision', 'F1', 'lossValue']:\n",
        "\n",
        "            total = []\n",
        "\n",
        "            for val in x:\n",
        "                total.append(val[j])\n",
        "\n",
        "            file.write(j + ' : mean : ' + str(np.mean(total)) + ' std : ' + str(np.std(total))  + '\\n')\n",
        "\n",
        "        file.write('\\n\\n______________________________\\n')\n",
        "    file.close();\n",
        "\n",
        "    index = 0\n",
        "\n",
        "    for x in [trainning_result, validation_result]:\n",
        "\n",
        "        tprs = []\n",
        "        aucs = []\n",
        "        mean_fpr = np.linspace(0, 1, 100)\n",
        "\n",
        "        i = 0\n",
        "\n",
        "        for val in x:\n",
        "            tpr = val['tpr']\n",
        "            fpr = val['fpr']\n",
        "            tprs.append(interp(mean_fpr, fpr, tpr))\n",
        "            tprs[-1][0] = 0.0\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            aucs.append(roc_auc)\n",
        "            plt.plot(fpr, tpr, lw=1, alpha=0.3,label='ROC fold %d (AUC = %0.2f)' % (i+1, roc_auc))\n",
        "\n",
        "            i += 1\n",
        "\n",
        "        print;\n",
        "\n",
        "        plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',label='Random', alpha=.8)\n",
        "\n",
        "        mean_tpr = np.mean(tprs, axis=0)\n",
        "        mean_tpr[-1] = 1.0\n",
        "        mean_auc = auc(mean_fpr, mean_tpr)\n",
        "        std_auc = np.std(aucs)\n",
        "        plt.plot(mean_fpr, mean_tpr, color='b',\n",
        "                 label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
        "                 lw=2, alpha=.8)\n",
        "\n",
        "        std_tpr = np.std(tprs, axis=0)\n",
        "        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
        "        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
        "        plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
        "                         label=r'$\\pm$ 1 std. dev.')\n",
        "\n",
        "        plt.xlim([-0.05, 1.05])\n",
        "        plt.ylim([-0.05, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver operating characteristic curve')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "\n",
        "        title = ''\n",
        "\n",
        "        if index == 0:\n",
        "            title = 'training_'\n",
        "        if index == 1:\n",
        "            title = 'validation_'\n",
        "      \n",
        "\n",
        "        plt.savefig( OutputDir + '/' + title +'ROC.png')\n",
        "        plt.close('all');\n",
        "\n",
        "        index += 1;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ9LyHZj0ISC",
        "outputId": "53c835d6-126e-450d-f001-dc51ac236eeb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid (5878, 64, 64)\n",
            "valid 5878\n",
            "train (47024, 64, 64)\n",
            "train 47024\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 64, 320)           246080    \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 53, 320)           1229120   \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 26, 320)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 26, 320)           0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 64)               90368     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                1040      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,566,625\n",
            "Trainable params: 1,566,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 47024 samples, validate on 5878 samples\n",
            "Epoch 1/50\n",
            "47024/47024 [==============================] - ETA: 0s - loss: 0.3230 - accuracy: 0.8639"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47024/47024 [==============================] - 71s 2ms/sample - loss: 0.3230 - accuracy: 0.8639 - val_loss: 0.3194 - val_accuracy: 0.8300 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.2137 - accuracy: 0.9160 - val_loss: 0.3858 - val_accuracy: 0.8095 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.1770 - accuracy: 0.9327 - val_loss: 0.4038 - val_accuracy: 0.8049 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.1549 - accuracy: 0.9423 - val_loss: 0.4922 - val_accuracy: 0.7890 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.1360 - accuracy: 0.9501 - val_loss: 0.4255 - val_accuracy: 0.7902 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.1250 - accuracy: 0.9540 - val_loss: 0.4461 - val_accuracy: 0.7933 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.1159 - accuracy: 0.9561 - val_loss: 0.3770 - val_accuracy: 0.8319 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.1063 - accuracy: 0.9618 - val_loss: 0.4499 - val_accuracy: 0.8346 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0977 - accuracy: 0.9642 - val_loss: 0.4380 - val_accuracy: 0.8147 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0872 - accuracy: 0.9678 - val_loss: 0.3803 - val_accuracy: 0.8416 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0845 - accuracy: 0.9680 - val_loss: 0.5456 - val_accuracy: 0.8243 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0773 - accuracy: 0.9714 - val_loss: 0.5835 - val_accuracy: 0.7901 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0744 - accuracy: 0.9719 - val_loss: 0.6251 - val_accuracy: 0.8401 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0684 - accuracy: 0.9757 - val_loss: 0.4254 - val_accuracy: 0.8469 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0646 - accuracy: 0.9764 - val_loss: 0.7721 - val_accuracy: 0.7974 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0594 - accuracy: 0.9786 - val_loss: 0.8895 - val_accuracy: 0.8265 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0568 - accuracy: 0.9793 - val_loss: 0.5465 - val_accuracy: 0.8375 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0508 - accuracy: 0.9809 - val_loss: 0.7753 - val_accuracy: 0.8175 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0482 - accuracy: 0.9827 - val_loss: 0.6513 - val_accuracy: 0.8566 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0463 - accuracy: 0.9831 - val_loss: 0.6473 - val_accuracy: 0.8515 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0417 - accuracy: 0.9848 - val_loss: 0.8068 - val_accuracy: 0.8333 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0214 - accuracy: 0.9926 - val_loss: 1.2702 - val_accuracy: 0.8156 - lr: 1.0000e-04\n",
            "Epoch 23/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0137 - accuracy: 0.9954 - val_loss: 1.4323 - val_accuracy: 0.8120 - lr: 1.0000e-04\n",
            "Epoch 24/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0126 - accuracy: 0.9960 - val_loss: 1.4665 - val_accuracy: 0.8212 - lr: 1.0000e-04\n",
            "Epoch 25/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0108 - accuracy: 0.9966 - val_loss: 1.7126 - val_accuracy: 0.8129 - lr: 1.0000e-04\n",
            "Epoch 26/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0104 - accuracy: 0.9969 - val_loss: 1.7171 - val_accuracy: 0.8129 - lr: 1.0000e-04\n",
            "Epoch 27/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0088 - accuracy: 0.9972 - val_loss: 1.8710 - val_accuracy: 0.8103 - lr: 1.0000e-04\n",
            "Epoch 28/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0088 - accuracy: 0.9972 - val_loss: 1.8076 - val_accuracy: 0.8185 - lr: 1.0000e-04\n",
            "Epoch 29/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0081 - accuracy: 0.9975 - val_loss: 1.7870 - val_accuracy: 0.8222 - lr: 1.0000e-04\n",
            "Epoch 30/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0073 - accuracy: 0.9976 - val_loss: 1.9108 - val_accuracy: 0.8236 - lr: 1.0000e-04\n",
            "Epoch 31/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0063 - accuracy: 0.9980 - val_loss: 2.0879 - val_accuracy: 0.8171 - lr: 1.0000e-04\n",
            "Epoch 32/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0066 - accuracy: 0.9978 - val_loss: 2.0029 - val_accuracy: 0.8207 - lr: 1.0000e-04\n",
            "Epoch 33/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0056 - accuracy: 0.9981 - val_loss: 2.0277 - val_accuracy: 0.8229 - lr: 1.0000e-04\n",
            "Epoch 34/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0050 - accuracy: 0.9984 - val_loss: 2.1356 - val_accuracy: 0.8195 - lr: 1.0000e-04\n",
            "Epoch 35/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0047 - accuracy: 0.9984 - val_loss: 2.1946 - val_accuracy: 0.8220 - lr: 1.0000e-04\n",
            "Epoch 36/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0047 - accuracy: 0.9984 - val_loss: 2.1998 - val_accuracy: 0.8306 - lr: 1.0000e-04\n",
            "Epoch 37/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0047 - accuracy: 0.9985 - val_loss: 2.3935 - val_accuracy: 0.8188 - lr: 1.0000e-04\n",
            "Epoch 38/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0045 - accuracy: 0.9986 - val_loss: 2.2740 - val_accuracy: 0.8217 - lr: 1.0000e-04\n",
            "Epoch 39/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0046 - accuracy: 0.9987 - val_loss: 2.5681 - val_accuracy: 0.8130 - lr: 1.0000e-04\n",
            "Epoch 40/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0037 - accuracy: 0.9988 - val_loss: 2.2813 - val_accuracy: 0.8246 - lr: 1.0000e-04\n",
            "Epoch 41/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0040 - accuracy: 0.9988 - val_loss: 2.0711 - val_accuracy: 0.8304 - lr: 1.0000e-04\n",
            "Epoch 42/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0034 - accuracy: 0.9991 - val_loss: 2.2036 - val_accuracy: 0.8246 - lr: 1.0000e-05\n",
            "Epoch 43/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0028 - accuracy: 0.9992 - val_loss: 2.2433 - val_accuracy: 0.8260 - lr: 1.0000e-05\n",
            "Epoch 44/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0028 - accuracy: 0.9991 - val_loss: 2.2907 - val_accuracy: 0.8237 - lr: 1.0000e-05\n",
            "Epoch 45/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0027 - accuracy: 0.9992 - val_loss: 2.3310 - val_accuracy: 0.8215 - lr: 1.0000e-05\n",
            "Epoch 46/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0023 - accuracy: 0.9993 - val_loss: 2.3617 - val_accuracy: 0.8212 - lr: 1.0000e-05\n",
            "Epoch 47/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0021 - accuracy: 0.9994 - val_loss: 2.4473 - val_accuracy: 0.8207 - lr: 1.0000e-05\n",
            "Epoch 48/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0028 - accuracy: 0.9991 - val_loss: 2.5289 - val_accuracy: 0.8175 - lr: 1.0000e-05\n",
            "Epoch 49/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0026 - accuracy: 0.9993 - val_loss: 2.4361 - val_accuracy: 0.8220 - lr: 1.0000e-05\n",
            "Epoch 50/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0023 - accuracy: 0.9993 - val_loss: 2.5432 - val_accuracy: 0.8190 - lr: 1.0000e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(47024, 1)\n",
            "(47024,)\n",
            "(5878, 1)\n",
            "(5878,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid (5878, 64, 64)\n",
            "valid 5878\n",
            "train (47024, 64, 64)\n",
            "train 47024\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_2 (Conv1D)           (None, 64, 320)           246080    \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 53, 320)           1229120   \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 26, 320)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 26, 320)           0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 64)               90368     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                1040      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,566,625\n",
            "Trainable params: 1,566,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 47024 samples, validate on 5878 samples\n",
            "Epoch 1/50\n",
            "47024/47024 [==============================] - ETA: 0s - loss: 0.2703 - accuracy: 0.8902"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.2703 - accuracy: 0.8902 - val_loss: 0.4410 - val_accuracy: 0.7833 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.1750 - accuracy: 0.9338 - val_loss: 0.4092 - val_accuracy: 0.8164 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.1395 - accuracy: 0.9489 - val_loss: 0.3740 - val_accuracy: 0.8465 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.1183 - accuracy: 0.9574 - val_loss: 0.4635 - val_accuracy: 0.8190 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.1042 - accuracy: 0.9620 - val_loss: 0.4271 - val_accuracy: 0.8394 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0982 - accuracy: 0.9658 - val_loss: 0.4522 - val_accuracy: 0.8209 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0839 - accuracy: 0.9700 - val_loss: 0.3847 - val_accuracy: 0.8489 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0775 - accuracy: 0.9721 - val_loss: 0.5519 - val_accuracy: 0.8164 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0724 - accuracy: 0.9739 - val_loss: 0.5550 - val_accuracy: 0.8283 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0638 - accuracy: 0.9766 - val_loss: 0.5045 - val_accuracy: 0.8471 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0588 - accuracy: 0.9788 - val_loss: 0.4998 - val_accuracy: 0.8649 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0564 - accuracy: 0.9794 - val_loss: 0.5560 - val_accuracy: 0.8593 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0552 - accuracy: 0.9804 - val_loss: 0.6611 - val_accuracy: 0.8564 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0497 - accuracy: 0.9822 - val_loss: 0.6284 - val_accuracy: 0.8431 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0451 - accuracy: 0.9837 - val_loss: 0.7336 - val_accuracy: 0.8579 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0432 - accuracy: 0.9852 - val_loss: 0.6056 - val_accuracy: 0.8568 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0443 - accuracy: 0.9851 - val_loss: 0.7664 - val_accuracy: 0.8331 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0369 - accuracy: 0.9871 - val_loss: 0.7308 - val_accuracy: 0.8641 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0346 - accuracy: 0.9877 - val_loss: 1.0978 - val_accuracy: 0.8175 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0352 - accuracy: 0.9872 - val_loss: 0.9467 - val_accuracy: 0.8525 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0327 - accuracy: 0.9886 - val_loss: 0.8317 - val_accuracy: 0.8389 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0283 - accuracy: 0.9895 - val_loss: 0.8224 - val_accuracy: 0.8637 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0280 - accuracy: 0.9895 - val_loss: 0.8881 - val_accuracy: 0.8401 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0153 - accuracy: 0.9949 - val_loss: 1.0445 - val_accuracy: 0.8505 - lr: 1.0000e-04\n",
            "Epoch 25/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0090 - accuracy: 0.9972 - val_loss: 1.3761 - val_accuracy: 0.8471 - lr: 1.0000e-04\n",
            "Epoch 26/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0078 - accuracy: 0.9972 - val_loss: 1.5293 - val_accuracy: 0.8474 - lr: 1.0000e-04\n",
            "Epoch 27/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0065 - accuracy: 0.9978 - val_loss: 1.6263 - val_accuracy: 0.8505 - lr: 1.0000e-04\n",
            "Epoch 28/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0054 - accuracy: 0.9980 - val_loss: 1.6609 - val_accuracy: 0.8537 - lr: 1.0000e-04\n",
            "Epoch 29/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0053 - accuracy: 0.9981 - val_loss: 1.8465 - val_accuracy: 0.8559 - lr: 1.0000e-04\n",
            "Epoch 30/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0048 - accuracy: 0.9984 - val_loss: 1.9593 - val_accuracy: 0.8527 - lr: 1.0000e-04\n",
            "Epoch 31/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0043 - accuracy: 0.9987 - val_loss: 2.0464 - val_accuracy: 0.8532 - lr: 1.0000e-04\n",
            "Epoch 32/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0037 - accuracy: 0.9990 - val_loss: 2.0360 - val_accuracy: 0.8535 - lr: 1.0000e-04\n",
            "Epoch 33/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0042 - accuracy: 0.9986 - val_loss: 2.0007 - val_accuracy: 0.8537 - lr: 1.0000e-04\n",
            "Epoch 34/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0031 - accuracy: 0.9989 - val_loss: 2.1408 - val_accuracy: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 35/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0031 - accuracy: 0.9990 - val_loss: 2.0739 - val_accuracy: 0.8501 - lr: 1.0000e-04\n",
            "Epoch 36/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0031 - accuracy: 0.9992 - val_loss: 2.2261 - val_accuracy: 0.8517 - lr: 1.0000e-04\n",
            "Epoch 37/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0027 - accuracy: 0.9993 - val_loss: 2.1973 - val_accuracy: 0.8511 - lr: 1.0000e-04\n",
            "Epoch 38/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0029 - accuracy: 0.9993 - val_loss: 2.2024 - val_accuracy: 0.8596 - lr: 1.0000e-04\n",
            "Epoch 39/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0026 - accuracy: 0.9992 - val_loss: 2.4338 - val_accuracy: 0.8556 - lr: 1.0000e-04\n",
            "Epoch 40/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0025 - accuracy: 0.9992 - val_loss: 2.4582 - val_accuracy: 0.8462 - lr: 1.0000e-04\n",
            "Epoch 41/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0027 - accuracy: 0.9989 - val_loss: 2.4837 - val_accuracy: 0.8540 - lr: 1.0000e-04\n",
            "Epoch 42/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0021 - accuracy: 0.9994 - val_loss: 2.5431 - val_accuracy: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 43/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0023 - accuracy: 0.9993 - val_loss: 2.7414 - val_accuracy: 0.8457 - lr: 1.0000e-04\n",
            "Epoch 44/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0015 - accuracy: 0.9996 - val_loss: 2.7461 - val_accuracy: 0.8474 - lr: 1.0000e-05\n",
            "Epoch 45/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0019 - accuracy: 0.9995 - val_loss: 2.7303 - val_accuracy: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 46/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0013 - accuracy: 0.9997 - val_loss: 2.7524 - val_accuracy: 0.8471 - lr: 1.0000e-05\n",
            "Epoch 47/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0012 - accuracy: 0.9997 - val_loss: 2.7121 - val_accuracy: 0.8499 - lr: 1.0000e-05\n",
            "Epoch 48/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0012 - accuracy: 0.9997 - val_loss: 2.7533 - val_accuracy: 0.8501 - lr: 1.0000e-05\n",
            "Epoch 49/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0013 - accuracy: 0.9996 - val_loss: 2.7185 - val_accuracy: 0.8506 - lr: 1.0000e-05\n",
            "Epoch 50/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 9.3877e-04 - accuracy: 0.9998 - val_loss: 2.7734 - val_accuracy: 0.8505 - lr: 1.0000e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(47024, 1)\n",
            "(47024,)\n",
            "(5878, 1)\n",
            "(5878,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid (5878, 64, 64)\n",
            "valid 5878\n",
            "train (47024, 64, 64)\n",
            "train 47024\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_4 (Conv1D)           (None, 64, 320)           246080    \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 53, 320)           1229120   \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 26, 320)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 26, 320)           0         \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 64)               90368     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 16)                1040      \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,566,625\n",
            "Trainable params: 1,566,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 47024 samples, validate on 5878 samples\n",
            "Epoch 1/50\n",
            "47024/47024 [==============================] - ETA: 0s - loss: 0.2564 - accuracy: 0.8975"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47024/47024 [==============================] - 53s 1ms/sample - loss: 0.2564 - accuracy: 0.8975 - val_loss: 0.9179 - val_accuracy: 0.6222 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.1598 - accuracy: 0.9412 - val_loss: 0.8675 - val_accuracy: 0.6885 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.1329 - accuracy: 0.9520 - val_loss: 0.8120 - val_accuracy: 0.6973 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.1167 - accuracy: 0.9594 - val_loss: 0.7397 - val_accuracy: 0.6938 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.1056 - accuracy: 0.9628 - val_loss: 0.9118 - val_accuracy: 0.6996 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0953 - accuracy: 0.9652 - val_loss: 1.0088 - val_accuracy: 0.7001 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0915 - accuracy: 0.9663 - val_loss: 0.9246 - val_accuracy: 0.7288 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0844 - accuracy: 0.9705 - val_loss: 0.8303 - val_accuracy: 0.7198 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0765 - accuracy: 0.9719 - val_loss: 0.9186 - val_accuracy: 0.7220 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0729 - accuracy: 0.9726 - val_loss: 1.1843 - val_accuracy: 0.7474 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0655 - accuracy: 0.9757 - val_loss: 1.6378 - val_accuracy: 0.6892 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0611 - accuracy: 0.9772 - val_loss: 1.4940 - val_accuracy: 0.7038 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0558 - accuracy: 0.9794 - val_loss: 1.7898 - val_accuracy: 0.7190 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0529 - accuracy: 0.9795 - val_loss: 1.2546 - val_accuracy: 0.7234 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0486 - accuracy: 0.9821 - val_loss: 2.0988 - val_accuracy: 0.7149 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0449 - accuracy: 0.9835 - val_loss: 1.5563 - val_accuracy: 0.7338 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0444 - accuracy: 0.9845 - val_loss: 1.7280 - val_accuracy: 0.7360 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0412 - accuracy: 0.9852 - val_loss: 1.6125 - val_accuracy: 0.7319 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0376 - accuracy: 0.9870 - val_loss: 1.4468 - val_accuracy: 0.7523 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0333 - accuracy: 0.9880 - val_loss: 2.2321 - val_accuracy: 0.7161 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0312 - accuracy: 0.9880 - val_loss: 2.8531 - val_accuracy: 0.7186 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0309 - accuracy: 0.9899 - val_loss: 2.6996 - val_accuracy: 0.7174 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0292 - accuracy: 0.9898 - val_loss: 2.9591 - val_accuracy: 0.7361 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0249 - accuracy: 0.9913 - val_loss: 3.4929 - val_accuracy: 0.7099 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0137 - accuracy: 0.9953 - val_loss: 3.6100 - val_accuracy: 0.7246 - lr: 1.0000e-04\n",
            "Epoch 26/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0079 - accuracy: 0.9977 - val_loss: 4.2255 - val_accuracy: 0.7212 - lr: 1.0000e-04\n",
            "Epoch 27/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0069 - accuracy: 0.9978 - val_loss: 4.0722 - val_accuracy: 0.7314 - lr: 1.0000e-04\n",
            "Epoch 28/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0050 - accuracy: 0.9984 - val_loss: 4.5113 - val_accuracy: 0.7336 - lr: 1.0000e-04\n",
            "Epoch 29/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0044 - accuracy: 0.9987 - val_loss: 4.2543 - val_accuracy: 0.7326 - lr: 1.0000e-04\n",
            "Epoch 30/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0045 - accuracy: 0.9987 - val_loss: 5.0583 - val_accuracy: 0.7278 - lr: 1.0000e-04\n",
            "Epoch 31/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0047 - accuracy: 0.9986 - val_loss: 4.6698 - val_accuracy: 0.7285 - lr: 1.0000e-04\n",
            "Epoch 32/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0035 - accuracy: 0.9990 - val_loss: 4.8518 - val_accuracy: 0.7312 - lr: 1.0000e-04\n",
            "Epoch 33/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0034 - accuracy: 0.9989 - val_loss: 4.9939 - val_accuracy: 0.7259 - lr: 1.0000e-04\n",
            "Epoch 34/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0032 - accuracy: 0.9993 - val_loss: 5.1584 - val_accuracy: 0.7273 - lr: 1.0000e-04\n",
            "Epoch 35/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0027 - accuracy: 0.9991 - val_loss: 5.1519 - val_accuracy: 0.7304 - lr: 1.0000e-04\n",
            "Epoch 36/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0031 - accuracy: 0.9993 - val_loss: 5.2778 - val_accuracy: 0.7268 - lr: 1.0000e-04\n",
            "Epoch 37/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0021 - accuracy: 0.9994 - val_loss: 5.8086 - val_accuracy: 0.7208 - lr: 1.0000e-04\n",
            "Epoch 38/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0022 - accuracy: 0.9994 - val_loss: 5.5088 - val_accuracy: 0.7305 - lr: 1.0000e-04\n",
            "Epoch 39/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0027 - accuracy: 0.9992 - val_loss: 5.6501 - val_accuracy: 0.7305 - lr: 1.0000e-04\n",
            "Epoch 40/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0022 - accuracy: 0.9994 - val_loss: 5.4395 - val_accuracy: 0.7314 - lr: 1.0000e-04\n",
            "Epoch 41/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0023 - accuracy: 0.9994 - val_loss: 5.3063 - val_accuracy: 0.7290 - lr: 1.0000e-04\n",
            "Epoch 42/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0016 - accuracy: 0.9995 - val_loss: 5.7044 - val_accuracy: 0.7309 - lr: 1.0000e-04\n",
            "Epoch 43/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0026 - accuracy: 0.9992 - val_loss: 6.0575 - val_accuracy: 0.7344 - lr: 1.0000e-04\n",
            "Epoch 44/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0016 - accuracy: 0.9997 - val_loss: 6.5253 - val_accuracy: 0.7285 - lr: 1.0000e-04\n",
            "Epoch 45/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0016 - accuracy: 0.9996 - val_loss: 6.3127 - val_accuracy: 0.7280 - lr: 1.0000e-05\n",
            "Epoch 46/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0014 - accuracy: 0.9996 - val_loss: 6.4040 - val_accuracy: 0.7280 - lr: 1.0000e-05\n",
            "Epoch 47/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0014 - accuracy: 0.9997 - val_loss: 6.4739 - val_accuracy: 0.7283 - lr: 1.0000e-05\n",
            "Epoch 48/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0013 - accuracy: 0.9997 - val_loss: 6.6653 - val_accuracy: 0.7263 - lr: 1.0000e-05\n",
            "Epoch 49/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0010 - accuracy: 0.9998 - val_loss: 6.4734 - val_accuracy: 0.7280 - lr: 1.0000e-05\n",
            "Epoch 50/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0012 - accuracy: 0.9997 - val_loss: 6.3876 - val_accuracy: 0.7293 - lr: 1.0000e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(47024, 1)\n",
            "(47024,)\n",
            "(5878, 1)\n",
            "(5878,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid (5878, 64, 64)\n",
            "valid 5878\n",
            "train (47024, 64, 64)\n",
            "train 47024\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_6 (Conv1D)           (None, 64, 320)           246080    \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 53, 320)           1229120   \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 26, 320)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 26, 320)           0         \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 64)               90368     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                1040      \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,566,625\n",
            "Trainable params: 1,566,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 47024 samples, validate on 5878 samples\n",
            "Epoch 1/50\n",
            "47024/47024 [==============================] - ETA: 0s - loss: 0.3245 - accuracy: 0.8622"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.3245 - accuracy: 0.8622 - val_loss: 0.4026 - val_accuracy: 0.7759 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.2231 - accuracy: 0.9107 - val_loss: 0.4294 - val_accuracy: 0.7896 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.1844 - accuracy: 0.9256 - val_loss: 0.3471 - val_accuracy: 0.8433 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.1633 - accuracy: 0.9349 - val_loss: 0.3231 - val_accuracy: 0.8574 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.1467 - accuracy: 0.9413 - val_loss: 0.3483 - val_accuracy: 0.8576 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.1364 - accuracy: 0.9459 - val_loss: 0.3961 - val_accuracy: 0.8416 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.1228 - accuracy: 0.9512 - val_loss: 0.4934 - val_accuracy: 0.8564 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.1153 - accuracy: 0.9557 - val_loss: 0.3563 - val_accuracy: 0.8642 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.1060 - accuracy: 0.9586 - val_loss: 0.3542 - val_accuracy: 0.8806 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.1018 - accuracy: 0.9613 - val_loss: 0.3642 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0940 - accuracy: 0.9637 - val_loss: 0.4877 - val_accuracy: 0.8690 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0885 - accuracy: 0.9656 - val_loss: 0.4629 - val_accuracy: 0.8661 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0810 - accuracy: 0.9690 - val_loss: 0.6803 - val_accuracy: 0.8566 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0773 - accuracy: 0.9700 - val_loss: 0.4369 - val_accuracy: 0.8654 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0712 - accuracy: 0.9720 - val_loss: 0.5646 - val_accuracy: 0.8547 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0661 - accuracy: 0.9745 - val_loss: 0.5763 - val_accuracy: 0.8615 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0632 - accuracy: 0.9763 - val_loss: 0.5243 - val_accuracy: 0.8768 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0569 - accuracy: 0.9779 - val_loss: 0.6321 - val_accuracy: 0.8562 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0552 - accuracy: 0.9791 - val_loss: 0.6705 - val_accuracy: 0.8699 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0522 - accuracy: 0.9813 - val_loss: 0.6612 - val_accuracy: 0.8576 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0488 - accuracy: 0.9818 - val_loss: 0.9272 - val_accuracy: 0.8505 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0467 - accuracy: 0.9826 - val_loss: 0.8181 - val_accuracy: 0.8406 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0443 - accuracy: 0.9835 - val_loss: 0.6913 - val_accuracy: 0.8692 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0406 - accuracy: 0.9851 - val_loss: 0.8418 - val_accuracy: 0.8341 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0223 - accuracy: 0.9927 - val_loss: 1.0639 - val_accuracy: 0.8605 - lr: 1.0000e-04\n",
            "Epoch 26/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0148 - accuracy: 0.9947 - val_loss: 1.1075 - val_accuracy: 0.8685 - lr: 1.0000e-04\n",
            "Epoch 27/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0122 - accuracy: 0.9960 - val_loss: 1.2799 - val_accuracy: 0.8680 - lr: 1.0000e-04\n",
            "Epoch 28/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0109 - accuracy: 0.9960 - val_loss: 1.4379 - val_accuracy: 0.8647 - lr: 1.0000e-04\n",
            "Epoch 29/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0088 - accuracy: 0.9967 - val_loss: 1.4822 - val_accuracy: 0.8668 - lr: 1.0000e-04\n",
            "Epoch 30/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0088 - accuracy: 0.9971 - val_loss: 1.3458 - val_accuracy: 0.8736 - lr: 1.0000e-04\n",
            "Epoch 31/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0078 - accuracy: 0.9974 - val_loss: 1.6130 - val_accuracy: 0.8671 - lr: 1.0000e-04\n",
            "Epoch 32/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0069 - accuracy: 0.9976 - val_loss: 1.6680 - val_accuracy: 0.8658 - lr: 1.0000e-04\n",
            "Epoch 33/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0070 - accuracy: 0.9976 - val_loss: 1.6860 - val_accuracy: 0.8651 - lr: 1.0000e-04\n",
            "Epoch 34/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0050 - accuracy: 0.9982 - val_loss: 1.8164 - val_accuracy: 0.8687 - lr: 1.0000e-04\n",
            "Epoch 35/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0054 - accuracy: 0.9983 - val_loss: 1.8185 - val_accuracy: 0.8644 - lr: 1.0000e-04\n",
            "Epoch 36/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0049 - accuracy: 0.9983 - val_loss: 2.0111 - val_accuracy: 0.8627 - lr: 1.0000e-04\n",
            "Epoch 37/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0057 - accuracy: 0.9983 - val_loss: 1.7712 - val_accuracy: 0.8651 - lr: 1.0000e-04\n",
            "Epoch 38/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0047 - accuracy: 0.9985 - val_loss: 1.8991 - val_accuracy: 0.8663 - lr: 1.0000e-04\n",
            "Epoch 39/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0041 - accuracy: 0.9988 - val_loss: 2.1235 - val_accuracy: 0.8624 - lr: 1.0000e-04\n",
            "Epoch 40/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0042 - accuracy: 0.9986 - val_loss: 2.0202 - val_accuracy: 0.8619 - lr: 1.0000e-04\n",
            "Epoch 41/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0040 - accuracy: 0.9986 - val_loss: 1.9798 - val_accuracy: 0.8647 - lr: 1.0000e-04\n",
            "Epoch 42/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0045 - accuracy: 0.9985 - val_loss: 2.0131 - val_accuracy: 0.8625 - lr: 1.0000e-04\n",
            "Epoch 43/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0040 - accuracy: 0.9987 - val_loss: 1.9867 - val_accuracy: 0.8658 - lr: 1.0000e-04\n",
            "Epoch 44/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0037 - accuracy: 0.9989 - val_loss: 2.0798 - val_accuracy: 0.8581 - lr: 1.0000e-04\n",
            "Epoch 45/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0031 - accuracy: 0.9990 - val_loss: 2.0720 - val_accuracy: 0.8593 - lr: 1.0000e-05\n",
            "Epoch 46/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0033 - accuracy: 0.9990 - val_loss: 2.0604 - val_accuracy: 0.8595 - lr: 1.0000e-05\n",
            "Epoch 47/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0026 - accuracy: 0.9993 - val_loss: 2.0208 - val_accuracy: 0.8607 - lr: 1.0000e-05\n",
            "Epoch 48/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0024 - accuracy: 0.9994 - val_loss: 2.0721 - val_accuracy: 0.8598 - lr: 1.0000e-05\n",
            "Epoch 49/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0021 - accuracy: 0.9994 - val_loss: 2.0821 - val_accuracy: 0.8619 - lr: 1.0000e-05\n",
            "Epoch 50/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0024 - accuracy: 0.9993 - val_loss: 2.0746 - val_accuracy: 0.8620 - lr: 1.0000e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(47024, 1)\n",
            "(47024,)\n",
            "(5878, 1)\n",
            "(5878,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid (5878, 64, 64)\n",
            "valid 5878\n",
            "train (47024, 64, 64)\n",
            "train 47024\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_8 (Conv1D)           (None, 64, 320)           246080    \n",
            "                                                                 \n",
            " conv1d_9 (Conv1D)           (None, 53, 320)           1229120   \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPooling  (None, 26, 320)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 26, 320)           0         \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  (None, 64)               90368     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 16)                1040      \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,566,625\n",
            "Trainable params: 1,566,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 47024 samples, validate on 5878 samples\n",
            "Epoch 1/50\n",
            "47024/47024 [==============================] - ETA: 0s - loss: 0.3386 - accuracy: 0.8482"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47024/47024 [==============================] - 53s 1ms/sample - loss: 0.3386 - accuracy: 0.8482 - val_loss: 0.1632 - val_accuracy: 0.9456 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.3333 - accuracy: 0.8641 - val_loss: 0.1897 - val_accuracy: 0.9355 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.2884 - accuracy: 0.8749 - val_loss: 0.1736 - val_accuracy: 0.9314 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.2395 - accuracy: 0.8972 - val_loss: 0.1700 - val_accuracy: 0.9297 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.2150 - accuracy: 0.9100 - val_loss: 0.1436 - val_accuracy: 0.9559 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.1961 - accuracy: 0.9211 - val_loss: 0.1469 - val_accuracy: 0.9416 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.1856 - accuracy: 0.9261 - val_loss: 0.1645 - val_accuracy: 0.9328 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.1748 - accuracy: 0.9312 - val_loss: 0.1666 - val_accuracy: 0.9364 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.1612 - accuracy: 0.9361 - val_loss: 0.1339 - val_accuracy: 0.9493 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.1502 - accuracy: 0.9421 - val_loss: 0.1402 - val_accuracy: 0.9382 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.1420 - accuracy: 0.9447 - val_loss: 0.1617 - val_accuracy: 0.9270 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.1343 - accuracy: 0.9473 - val_loss: 0.1175 - val_accuracy: 0.9559 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.1273 - accuracy: 0.9500 - val_loss: 0.1796 - val_accuracy: 0.9223 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.1290 - accuracy: 0.9500 - val_loss: 0.1845 - val_accuracy: 0.9255 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.1189 - accuracy: 0.9546 - val_loss: 0.1904 - val_accuracy: 0.9342 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.1137 - accuracy: 0.9558 - val_loss: 0.2560 - val_accuracy: 0.8991 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.1083 - accuracy: 0.9584 - val_loss: 0.2452 - val_accuracy: 0.8988 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.1028 - accuracy: 0.9603 - val_loss: 0.2626 - val_accuracy: 0.9073 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.1045 - accuracy: 0.9604 - val_loss: 0.1884 - val_accuracy: 0.9267 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.1161 - accuracy: 0.9557 - val_loss: 0.2040 - val_accuracy: 0.9217 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0999 - accuracy: 0.9613 - val_loss: 0.1951 - val_accuracy: 0.9279 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0928 - accuracy: 0.9642 - val_loss: 0.2394 - val_accuracy: 0.9301 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0877 - accuracy: 0.9660 - val_loss: 0.2422 - val_accuracy: 0.9280 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0824 - accuracy: 0.9678 - val_loss: 0.2677 - val_accuracy: 0.9134 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0806 - accuracy: 0.9688 - val_loss: 0.3245 - val_accuracy: 0.9105 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0774 - accuracy: 0.9695 - val_loss: 0.2640 - val_accuracy: 0.9299 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0742 - accuracy: 0.9717 - val_loss: 0.3239 - val_accuracy: 0.9039 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0701 - accuracy: 0.9727 - val_loss: 0.2574 - val_accuracy: 0.9319 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0672 - accuracy: 0.9746 - val_loss: 0.3219 - val_accuracy: 0.9095 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0622 - accuracy: 0.9762 - val_loss: 0.3161 - val_accuracy: 0.9277 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0626 - accuracy: 0.9763 - val_loss: 0.3238 - val_accuracy: 0.9076 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0581 - accuracy: 0.9781 - val_loss: 0.3678 - val_accuracy: 0.9413 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0366 - accuracy: 0.9864 - val_loss: 0.4234 - val_accuracy: 0.9308 - lr: 1.0000e-04\n",
            "Epoch 34/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0306 - accuracy: 0.9886 - val_loss: 0.4505 - val_accuracy: 0.9335 - lr: 1.0000e-04\n",
            "Epoch 35/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0279 - accuracy: 0.9902 - val_loss: 0.4483 - val_accuracy: 0.9314 - lr: 1.0000e-04\n",
            "Epoch 36/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0265 - accuracy: 0.9904 - val_loss: 0.5608 - val_accuracy: 0.9251 - lr: 1.0000e-04\n",
            "Epoch 37/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0260 - accuracy: 0.9903 - val_loss: 0.5170 - val_accuracy: 0.9342 - lr: 1.0000e-04\n",
            "Epoch 38/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0234 - accuracy: 0.9917 - val_loss: 0.5819 - val_accuracy: 0.9265 - lr: 1.0000e-04\n",
            "Epoch 39/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0227 - accuracy: 0.9913 - val_loss: 0.5628 - val_accuracy: 0.9223 - lr: 1.0000e-04\n",
            "Epoch 40/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0218 - accuracy: 0.9923 - val_loss: 0.6192 - val_accuracy: 0.9231 - lr: 1.0000e-04\n",
            "Epoch 41/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.6372 - val_accuracy: 0.9274 - lr: 1.0000e-04\n",
            "Epoch 42/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0194 - accuracy: 0.9932 - val_loss: 0.6948 - val_accuracy: 0.9194 - lr: 1.0000e-04\n",
            "Epoch 43/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0185 - accuracy: 0.9933 - val_loss: 0.6168 - val_accuracy: 0.9347 - lr: 1.0000e-04\n",
            "Epoch 44/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0178 - accuracy: 0.9937 - val_loss: 0.6926 - val_accuracy: 0.9267 - lr: 1.0000e-04\n",
            "Epoch 45/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0181 - accuracy: 0.9939 - val_loss: 0.7367 - val_accuracy: 0.9231 - lr: 1.0000e-04\n",
            "Epoch 46/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0166 - accuracy: 0.9940 - val_loss: 0.7134 - val_accuracy: 0.9240 - lr: 1.0000e-04\n",
            "Epoch 47/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0164 - accuracy: 0.9940 - val_loss: 0.6575 - val_accuracy: 0.9304 - lr: 1.0000e-04\n",
            "Epoch 48/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0159 - accuracy: 0.9946 - val_loss: 0.7646 - val_accuracy: 0.9214 - lr: 1.0000e-04\n",
            "Epoch 49/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0168 - accuracy: 0.9940 - val_loss: 0.7094 - val_accuracy: 0.9304 - lr: 1.0000e-04\n",
            "Epoch 50/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0141 - accuracy: 0.9949 - val_loss: 0.8033 - val_accuracy: 0.9263 - lr: 1.0000e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(47024, 1)\n",
            "(47024,)\n",
            "(5878, 1)\n",
            "(5878,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid (5878, 64, 64)\n",
            "valid 5878\n",
            "train (47024, 64, 64)\n",
            "train 47024\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_10 (Conv1D)          (None, 64, 320)           246080    \n",
            "                                                                 \n",
            " conv1d_11 (Conv1D)          (None, 53, 320)           1229120   \n",
            "                                                                 \n",
            " max_pooling1d_5 (MaxPooling  (None, 26, 320)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 26, 320)           0         \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirectio  (None, 64)               90368     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 16)                1040      \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,566,625\n",
            "Trainable params: 1,566,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 47024 samples, validate on 5878 samples\n",
            "Epoch 1/50\n",
            "47024/47024 [==============================] - ETA: 0s - loss: 0.3401 - accuracy: 0.8502"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47024/47024 [==============================] - 56s 1ms/sample - loss: 0.3401 - accuracy: 0.8502 - val_loss: 0.2594 - val_accuracy: 0.8913 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.2333 - accuracy: 0.9039 - val_loss: 0.1916 - val_accuracy: 0.9306 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "47024/47024 [==============================] - 53s 1ms/sample - loss: 0.1884 - accuracy: 0.9257 - val_loss: 0.2496 - val_accuracy: 0.9049 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.1644 - accuracy: 0.9369 - val_loss: 0.2661 - val_accuracy: 0.8836 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.1471 - accuracy: 0.9426 - val_loss: 0.2672 - val_accuracy: 0.8988 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.1293 - accuracy: 0.9501 - val_loss: 0.2964 - val_accuracy: 0.8860 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.1190 - accuracy: 0.9540 - val_loss: 0.3143 - val_accuracy: 0.8979 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.1102 - accuracy: 0.9591 - val_loss: 0.3256 - val_accuracy: 0.9119 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.1019 - accuracy: 0.9611 - val_loss: 0.3193 - val_accuracy: 0.9170 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0971 - accuracy: 0.9645 - val_loss: 0.4177 - val_accuracy: 0.8979 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "47024/47024 [==============================] - 53s 1ms/sample - loss: 0.0901 - accuracy: 0.9653 - val_loss: 0.3129 - val_accuracy: 0.9044 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0855 - accuracy: 0.9669 - val_loss: 0.5410 - val_accuracy: 0.9025 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0749 - accuracy: 0.9716 - val_loss: 0.5953 - val_accuracy: 0.8841 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0719 - accuracy: 0.9723 - val_loss: 0.5149 - val_accuracy: 0.9066 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0674 - accuracy: 0.9732 - val_loss: 0.5551 - val_accuracy: 0.8989 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0633 - accuracy: 0.9757 - val_loss: 0.5438 - val_accuracy: 0.8949 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0606 - accuracy: 0.9775 - val_loss: 0.5375 - val_accuracy: 0.9059 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0573 - accuracy: 0.9787 - val_loss: 0.7745 - val_accuracy: 0.8947 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0511 - accuracy: 0.9807 - val_loss: 0.8286 - val_accuracy: 0.9034 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0474 - accuracy: 0.9823 - val_loss: 0.6546 - val_accuracy: 0.9035 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0495 - accuracy: 0.9811 - val_loss: 0.7061 - val_accuracy: 0.8937 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0429 - accuracy: 0.9842 - val_loss: 0.7840 - val_accuracy: 0.9030 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0247 - accuracy: 0.9913 - val_loss: 0.8325 - val_accuracy: 0.9093 - lr: 1.0000e-04\n",
            "Epoch 24/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0178 - accuracy: 0.9941 - val_loss: 1.0213 - val_accuracy: 0.9059 - lr: 1.0000e-04\n",
            "Epoch 25/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0148 - accuracy: 0.9947 - val_loss: 1.1623 - val_accuracy: 0.9005 - lr: 1.0000e-04\n",
            "Epoch 26/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0129 - accuracy: 0.9953 - val_loss: 1.1355 - val_accuracy: 0.9081 - lr: 1.0000e-04\n",
            "Epoch 27/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0118 - accuracy: 0.9961 - val_loss: 1.2217 - val_accuracy: 0.9054 - lr: 1.0000e-04\n",
            "Epoch 28/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0094 - accuracy: 0.9967 - val_loss: 1.3131 - val_accuracy: 0.9042 - lr: 1.0000e-04\n",
            "Epoch 29/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0097 - accuracy: 0.9964 - val_loss: 1.2796 - val_accuracy: 0.9051 - lr: 1.0000e-04\n",
            "Epoch 30/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0091 - accuracy: 0.9969 - val_loss: 1.3130 - val_accuracy: 0.9035 - lr: 1.0000e-04\n",
            "Epoch 31/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0079 - accuracy: 0.9972 - val_loss: 1.4326 - val_accuracy: 0.9051 - lr: 1.0000e-04\n",
            "Epoch 32/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0085 - accuracy: 0.9970 - val_loss: 1.4974 - val_accuracy: 0.9017 - lr: 1.0000e-04\n",
            "Epoch 33/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0081 - accuracy: 0.9973 - val_loss: 1.5984 - val_accuracy: 0.9018 - lr: 1.0000e-04\n",
            "Epoch 34/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0060 - accuracy: 0.9977 - val_loss: 1.5913 - val_accuracy: 0.9005 - lr: 1.0000e-04\n",
            "Epoch 35/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0065 - accuracy: 0.9979 - val_loss: 1.4557 - val_accuracy: 0.9098 - lr: 1.0000e-04\n",
            "Epoch 36/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0060 - accuracy: 0.9979 - val_loss: 1.5205 - val_accuracy: 0.9075 - lr: 1.0000e-04\n",
            "Epoch 37/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0055 - accuracy: 0.9983 - val_loss: 1.6580 - val_accuracy: 0.9066 - lr: 1.0000e-04\n",
            "Epoch 38/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0054 - accuracy: 0.9983 - val_loss: 1.7098 - val_accuracy: 0.9027 - lr: 1.0000e-04\n",
            "Epoch 39/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0044 - accuracy: 0.9985 - val_loss: 1.7825 - val_accuracy: 0.9040 - lr: 1.0000e-04\n",
            "Epoch 40/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0051 - accuracy: 0.9983 - val_loss: 1.7074 - val_accuracy: 0.9100 - lr: 1.0000e-04\n",
            "Epoch 41/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0048 - accuracy: 0.9983 - val_loss: 1.7716 - val_accuracy: 0.9059 - lr: 1.0000e-04\n",
            "Epoch 42/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0045 - accuracy: 0.9986 - val_loss: 1.7543 - val_accuracy: 0.9013 - lr: 1.0000e-04\n",
            "Epoch 43/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0035 - accuracy: 0.9989 - val_loss: 1.7866 - val_accuracy: 0.9017 - lr: 1.0000e-05\n",
            "Epoch 44/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0041 - accuracy: 0.9987 - val_loss: 1.7942 - val_accuracy: 0.9020 - lr: 1.0000e-05\n",
            "Epoch 45/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0033 - accuracy: 0.9990 - val_loss: 1.7548 - val_accuracy: 0.9029 - lr: 1.0000e-05\n",
            "Epoch 46/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0030 - accuracy: 0.9990 - val_loss: 1.7948 - val_accuracy: 0.9027 - lr: 1.0000e-05\n",
            "Epoch 47/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0037 - accuracy: 0.9989 - val_loss: 1.7779 - val_accuracy: 0.9044 - lr: 1.0000e-05\n",
            "Epoch 48/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0028 - accuracy: 0.9992 - val_loss: 1.8307 - val_accuracy: 0.9042 - lr: 1.0000e-05\n",
            "Epoch 49/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0027 - accuracy: 0.9991 - val_loss: 1.8196 - val_accuracy: 0.9039 - lr: 1.0000e-05\n",
            "Epoch 50/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0024 - accuracy: 0.9992 - val_loss: 1.8523 - val_accuracy: 0.9027 - lr: 1.0000e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(47024, 1)\n",
            "(47024,)\n",
            "(5878, 1)\n",
            "(5878,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid (5878, 64, 64)\n",
            "valid 5878\n",
            "train (47024, 64, 64)\n",
            "train 47024\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_12 (Conv1D)          (None, 64, 320)           246080    \n",
            "                                                                 \n",
            " conv1d_13 (Conv1D)          (None, 53, 320)           1229120   \n",
            "                                                                 \n",
            " max_pooling1d_6 (MaxPooling  (None, 26, 320)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 26, 320)           0         \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirectio  (None, 64)               90368     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 16)                1040      \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,566,625\n",
            "Trainable params: 1,566,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 47024 samples, validate on 5878 samples\n",
            "Epoch 1/50\n",
            "47024/47024 [==============================] - ETA: 0s - loss: 0.3626 - accuracy: 0.8343"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47024/47024 [==============================] - 54s 1ms/sample - loss: 0.3626 - accuracy: 0.8343 - val_loss: 0.1692 - val_accuracy: 0.9347 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.2366 - accuracy: 0.9029 - val_loss: 0.1763 - val_accuracy: 0.9190 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.1979 - accuracy: 0.9218 - val_loss: 0.1290 - val_accuracy: 0.9549 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.1709 - accuracy: 0.9342 - val_loss: 0.2198 - val_accuracy: 0.9081 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.1543 - accuracy: 0.9409 - val_loss: 0.1143 - val_accuracy: 0.9541 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.1408 - accuracy: 0.9458 - val_loss: 0.1093 - val_accuracy: 0.9541 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.1300 - accuracy: 0.9507 - val_loss: 0.1512 - val_accuracy: 0.9464 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.1199 - accuracy: 0.9547 - val_loss: 0.1339 - val_accuracy: 0.9507 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.1105 - accuracy: 0.9582 - val_loss: 0.1764 - val_accuracy: 0.9505 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.1070 - accuracy: 0.9586 - val_loss: 0.1540 - val_accuracy: 0.9527 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0967 - accuracy: 0.9625 - val_loss: 0.1436 - val_accuracy: 0.9536 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0928 - accuracy: 0.9646 - val_loss: 0.1123 - val_accuracy: 0.9610 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0872 - accuracy: 0.9673 - val_loss: 0.1430 - val_accuracy: 0.9544 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0845 - accuracy: 0.9685 - val_loss: 0.1086 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0758 - accuracy: 0.9711 - val_loss: 0.1515 - val_accuracy: 0.9530 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0733 - accuracy: 0.9724 - val_loss: 0.1387 - val_accuracy: 0.9614 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0678 - accuracy: 0.9745 - val_loss: 0.1864 - val_accuracy: 0.9503 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0641 - accuracy: 0.9756 - val_loss: 0.1562 - val_accuracy: 0.9631 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0601 - accuracy: 0.9771 - val_loss: 0.1652 - val_accuracy: 0.9602 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0573 - accuracy: 0.9779 - val_loss: 0.1676 - val_accuracy: 0.9539 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0539 - accuracy: 0.9791 - val_loss: 0.1665 - val_accuracy: 0.9597 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0522 - accuracy: 0.9806 - val_loss: 0.1905 - val_accuracy: 0.9568 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0479 - accuracy: 0.9821 - val_loss: 0.2354 - val_accuracy: 0.9622 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0459 - accuracy: 0.9827 - val_loss: 0.1809 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0416 - accuracy: 0.9844 - val_loss: 0.2807 - val_accuracy: 0.9520 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0426 - accuracy: 0.9849 - val_loss: 0.2435 - val_accuracy: 0.9568 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0417 - accuracy: 0.9849 - val_loss: 0.2123 - val_accuracy: 0.9609 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0355 - accuracy: 0.9869 - val_loss: 0.2129 - val_accuracy: 0.9597 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0362 - accuracy: 0.9874 - val_loss: 0.2693 - val_accuracy: 0.9578 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0342 - accuracy: 0.9879 - val_loss: 0.2248 - val_accuracy: 0.9568 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0353 - accuracy: 0.9867 - val_loss: 0.2316 - val_accuracy: 0.9627 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0310 - accuracy: 0.9886 - val_loss: 0.2616 - val_accuracy: 0.9588 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0319 - accuracy: 0.9886 - val_loss: 0.2910 - val_accuracy: 0.9568 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0284 - accuracy: 0.9903 - val_loss: 0.2137 - val_accuracy: 0.9605 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.3211 - val_accuracy: 0.9581 - lr: 1.0000e-04\n",
            "Epoch 36/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.3357 - val_accuracy: 0.9573 - lr: 1.0000e-04\n",
            "Epoch 37/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.3735 - val_accuracy: 0.9573 - lr: 1.0000e-04\n",
            "Epoch 38/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.4097 - val_accuracy: 0.9600 - lr: 1.0000e-04\n",
            "Epoch 39/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.4085 - val_accuracy: 0.9578 - lr: 1.0000e-04\n",
            "Epoch 40/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.4545 - val_accuracy: 0.9571 - lr: 1.0000e-04\n",
            "Epoch 41/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.4789 - val_accuracy: 0.9578 - lr: 1.0000e-04\n",
            "Epoch 42/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.4992 - val_accuracy: 0.9588 - lr: 1.0000e-04\n",
            "Epoch 43/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.4948 - val_accuracy: 0.9564 - lr: 1.0000e-04\n",
            "Epoch 44/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.5141 - val_accuracy: 0.9578 - lr: 1.0000e-04\n",
            "Epoch 45/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.5448 - val_accuracy: 0.9578 - lr: 1.0000e-04\n",
            "Epoch 46/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.5042 - val_accuracy: 0.9583 - lr: 1.0000e-04\n",
            "Epoch 47/50\n",
            "47024/47024 [==============================] - 47s 1ms/sample - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.4966 - val_accuracy: 0.9616 - lr: 1.0000e-04\n",
            "Epoch 48/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.5068 - val_accuracy: 0.9614 - lr: 1.0000e-04\n",
            "Epoch 49/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.5858 - val_accuracy: 0.9581 - lr: 1.0000e-04\n",
            "Epoch 50/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.6126 - val_accuracy: 0.9571 - lr: 1.0000e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(47024, 1)\n",
            "(47024,)\n",
            "(5878, 1)\n",
            "(5878,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid (5878, 64, 64)\n",
            "valid 5878\n",
            "train (47024, 64, 64)\n",
            "train 47024\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_14 (Conv1D)          (None, 64, 320)           246080    \n",
            "                                                                 \n",
            " conv1d_15 (Conv1D)          (None, 53, 320)           1229120   \n",
            "                                                                 \n",
            " max_pooling1d_7 (MaxPooling  (None, 26, 320)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 26, 320)           0         \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirectio  (None, 64)               90368     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 16)                1040      \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,566,625\n",
            "Trainable params: 1,566,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 47024 samples, validate on 5878 samples\n",
            "Epoch 1/50\n",
            "47024/47024 [==============================] - ETA: 0s - loss: 0.3832 - accuracy: 0.8247"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47024/47024 [==============================] - 56s 1ms/sample - loss: 0.3832 - accuracy: 0.8247 - val_loss: 0.1944 - val_accuracy: 0.9117 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.2412 - accuracy: 0.9037 - val_loss: 0.1895 - val_accuracy: 0.9148 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.2010 - accuracy: 0.9218 - val_loss: 0.2055 - val_accuracy: 0.9030 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.1798 - accuracy: 0.9307 - val_loss: 0.1615 - val_accuracy: 0.9347 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.1648 - accuracy: 0.9378 - val_loss: 0.1675 - val_accuracy: 0.9302 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.1505 - accuracy: 0.9432 - val_loss: 0.2432 - val_accuracy: 0.9061 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.1359 - accuracy: 0.9495 - val_loss: 0.2463 - val_accuracy: 0.9109 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.1282 - accuracy: 0.9531 - val_loss: 0.2174 - val_accuracy: 0.9144 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.1208 - accuracy: 0.9552 - val_loss: 0.1871 - val_accuracy: 0.9311 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.1091 - accuracy: 0.9583 - val_loss: 0.2790 - val_accuracy: 0.9051 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.1047 - accuracy: 0.9618 - val_loss: 0.2769 - val_accuracy: 0.9136 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0976 - accuracy: 0.9629 - val_loss: 0.2127 - val_accuracy: 0.9223 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0917 - accuracy: 0.9656 - val_loss: 0.2587 - val_accuracy: 0.9214 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0866 - accuracy: 0.9682 - val_loss: 0.2805 - val_accuracy: 0.9197 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0815 - accuracy: 0.9705 - val_loss: 0.3646 - val_accuracy: 0.8991 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0764 - accuracy: 0.9713 - val_loss: 0.3634 - val_accuracy: 0.9165 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0731 - accuracy: 0.9731 - val_loss: 0.3096 - val_accuracy: 0.9073 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0687 - accuracy: 0.9755 - val_loss: 0.4151 - val_accuracy: 0.9078 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0696 - accuracy: 0.9745 - val_loss: 0.3085 - val_accuracy: 0.9178 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0607 - accuracy: 0.9782 - val_loss: 0.2594 - val_accuracy: 0.9209 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0546 - accuracy: 0.9802 - val_loss: 0.3552 - val_accuracy: 0.9153 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0567 - accuracy: 0.9789 - val_loss: 0.3760 - val_accuracy: 0.9219 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0533 - accuracy: 0.9807 - val_loss: 0.3862 - val_accuracy: 0.9166 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0491 - accuracy: 0.9827 - val_loss: 0.3599 - val_accuracy: 0.9216 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "47024/47024 [==============================] - 52s 1ms/sample - loss: 0.0293 - accuracy: 0.9900 - val_loss: 0.4562 - val_accuracy: 0.9195 - lr: 1.0000e-04\n",
            "Epoch 26/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.4700 - val_accuracy: 0.9212 - lr: 1.0000e-04\n",
            "Epoch 27/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.4854 - val_accuracy: 0.9219 - lr: 1.0000e-04\n",
            "Epoch 28/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0167 - accuracy: 0.9948 - val_loss: 0.5774 - val_accuracy: 0.9190 - lr: 1.0000e-04\n",
            "Epoch 29/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.5649 - val_accuracy: 0.9214 - lr: 1.0000e-04\n",
            "Epoch 30/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0140 - accuracy: 0.9956 - val_loss: 0.6032 - val_accuracy: 0.9200 - lr: 1.0000e-04\n",
            "Epoch 31/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0133 - accuracy: 0.9959 - val_loss: 0.5844 - val_accuracy: 0.9209 - lr: 1.0000e-04\n",
            "Epoch 32/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0114 - accuracy: 0.9967 - val_loss: 0.7298 - val_accuracy: 0.9160 - lr: 1.0000e-04\n",
            "Epoch 33/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.6491 - val_accuracy: 0.9200 - lr: 1.0000e-04\n",
            "Epoch 34/50\n",
            "47024/47024 [==============================] - 51s 1ms/sample - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.7011 - val_accuracy: 0.9216 - lr: 1.0000e-04\n",
            "Epoch 35/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.6775 - val_accuracy: 0.9200 - lr: 1.0000e-04\n",
            "Epoch 36/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.6971 - val_accuracy: 0.9240 - lr: 1.0000e-04\n",
            "Epoch 37/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.7535 - val_accuracy: 0.9199 - lr: 1.0000e-04\n",
            "Epoch 38/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.7087 - val_accuracy: 0.9245 - lr: 1.0000e-04\n",
            "Epoch 39/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.7214 - val_accuracy: 0.9228 - lr: 1.0000e-04\n",
            "Epoch 40/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.7772 - val_accuracy: 0.9163 - lr: 1.0000e-04\n",
            "Epoch 41/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0083 - accuracy: 0.9980 - val_loss: 0.8083 - val_accuracy: 0.9175 - lr: 1.0000e-04\n",
            "Epoch 42/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0077 - accuracy: 0.9980 - val_loss: 0.7801 - val_accuracy: 0.9231 - lr: 1.0000e-04\n",
            "Epoch 43/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.7747 - val_accuracy: 0.9207 - lr: 1.0000e-04\n",
            "Epoch 44/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.8861 - val_accuracy: 0.9149 - lr: 1.0000e-04\n",
            "Epoch 45/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.8286 - val_accuracy: 0.9204 - lr: 1.0000e-05\n",
            "Epoch 46/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.8286 - val_accuracy: 0.9206 - lr: 1.0000e-05\n",
            "Epoch 47/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.8361 - val_accuracy: 0.9209 - lr: 1.0000e-05\n",
            "Epoch 48/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.8590 - val_accuracy: 0.9194 - lr: 1.0000e-05\n",
            "Epoch 49/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.8616 - val_accuracy: 0.9199 - lr: 1.0000e-05\n",
            "Epoch 50/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.8553 - val_accuracy: 0.9197 - lr: 1.0000e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(47024, 1)\n",
            "(47024,)\n",
            "(5878, 1)\n",
            "(5878,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid (5878, 64, 64)\n",
            "valid 5878\n",
            "train (47024, 64, 64)\n",
            "train 47024\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_16 (Conv1D)          (None, 64, 320)           246080    \n",
            "                                                                 \n",
            " conv1d_17 (Conv1D)          (None, 53, 320)           1229120   \n",
            "                                                                 \n",
            " max_pooling1d_8 (MaxPooling  (None, 26, 320)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 26, 320)           0         \n",
            "                                                                 \n",
            " bidirectional_8 (Bidirectio  (None, 64)               90368     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 16)                1040      \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,566,625\n",
            "Trainable params: 1,566,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 47024 samples, validate on 5878 samples\n",
            "Epoch 1/50\n",
            "47024/47024 [==============================] - ETA: 0s - loss: 0.3557 - accuracy: 0.8403"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47024/47024 [==============================] - 54s 1ms/sample - loss: 0.3557 - accuracy: 0.8403 - val_loss: 0.1550 - val_accuracy: 0.9376 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.2385 - accuracy: 0.8991 - val_loss: 0.1347 - val_accuracy: 0.9381 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.1947 - accuracy: 0.9223 - val_loss: 0.1203 - val_accuracy: 0.9544 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.1756 - accuracy: 0.9304 - val_loss: 0.1096 - val_accuracy: 0.9532 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.1534 - accuracy: 0.9399 - val_loss: 0.1218 - val_accuracy: 0.9503 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.1474 - accuracy: 0.9419 - val_loss: 0.1253 - val_accuracy: 0.9422 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.1341 - accuracy: 0.9478 - val_loss: 0.0897 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.1254 - accuracy: 0.9513 - val_loss: 0.0774 - val_accuracy: 0.9702 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.1163 - accuracy: 0.9564 - val_loss: 0.0998 - val_accuracy: 0.9638 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.1092 - accuracy: 0.9579 - val_loss: 0.0915 - val_accuracy: 0.9648 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.1026 - accuracy: 0.9610 - val_loss: 0.0919 - val_accuracy: 0.9610 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0935 - accuracy: 0.9643 - val_loss: 0.1027 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0865 - accuracy: 0.9665 - val_loss: 0.1100 - val_accuracy: 0.9578 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0854 - accuracy: 0.9672 - val_loss: 0.0931 - val_accuracy: 0.9668 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0792 - accuracy: 0.9695 - val_loss: 0.1019 - val_accuracy: 0.9566 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0728 - accuracy: 0.9722 - val_loss: 0.0940 - val_accuracy: 0.9697 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0693 - accuracy: 0.9740 - val_loss: 0.0948 - val_accuracy: 0.9685 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0641 - accuracy: 0.9752 - val_loss: 0.1104 - val_accuracy: 0.9600 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0599 - accuracy: 0.9773 - val_loss: 0.1008 - val_accuracy: 0.9682 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0578 - accuracy: 0.9788 - val_loss: 0.1353 - val_accuracy: 0.9621 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0541 - accuracy: 0.9790 - val_loss: 0.1028 - val_accuracy: 0.9685 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0510 - accuracy: 0.9811 - val_loss: 0.1519 - val_accuracy: 0.9575 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0471 - accuracy: 0.9824 - val_loss: 0.1186 - val_accuracy: 0.9643 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0455 - accuracy: 0.9831 - val_loss: 0.1047 - val_accuracy: 0.9677 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0387 - accuracy: 0.9850 - val_loss: 0.1498 - val_accuracy: 0.9660 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0440 - accuracy: 0.9844 - val_loss: 0.1153 - val_accuracy: 0.9748 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0434 - accuracy: 0.9841 - val_loss: 0.1500 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0372 - accuracy: 0.9867 - val_loss: 0.1505 - val_accuracy: 0.9639 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0193 - accuracy: 0.9935 - val_loss: 0.1585 - val_accuracy: 0.9672 - lr: 1.0000e-04\n",
            "Epoch 30/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.1680 - val_accuracy: 0.9690 - lr: 1.0000e-04\n",
            "Epoch 31/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.1859 - val_accuracy: 0.9670 - lr: 1.0000e-04\n",
            "Epoch 32/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.2007 - val_accuracy: 0.9672 - lr: 1.0000e-04\n",
            "Epoch 33/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.2020 - val_accuracy: 0.9694 - lr: 1.0000e-04\n",
            "Epoch 34/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.2207 - val_accuracy: 0.9670 - lr: 1.0000e-04\n",
            "Epoch 35/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.2310 - val_accuracy: 0.9672 - lr: 1.0000e-04\n",
            "Epoch 36/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.2326 - val_accuracy: 0.9685 - lr: 1.0000e-04\n",
            "Epoch 37/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.2374 - val_accuracy: 0.9684 - lr: 1.0000e-04\n",
            "Epoch 38/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.2190 - val_accuracy: 0.9682 - lr: 1.0000e-04\n",
            "Epoch 39/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.2459 - val_accuracy: 0.9677 - lr: 1.0000e-04\n",
            "Epoch 40/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.2423 - val_accuracy: 0.9680 - lr: 1.0000e-04\n",
            "Epoch 41/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.2472 - val_accuracy: 0.9678 - lr: 1.0000e-04\n",
            "Epoch 42/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.2440 - val_accuracy: 0.9689 - lr: 1.0000e-04\n",
            "Epoch 43/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.2578 - val_accuracy: 0.9678 - lr: 1.0000e-04\n",
            "Epoch 44/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.2818 - val_accuracy: 0.9682 - lr: 1.0000e-04\n",
            "Epoch 45/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.2622 - val_accuracy: 0.9712 - lr: 1.0000e-04\n",
            "Epoch 46/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.2785 - val_accuracy: 0.9697 - lr: 1.0000e-04\n",
            "Epoch 47/50\n",
            "47024/47024 [==============================] - 48s 1ms/sample - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.2726 - val_accuracy: 0.9677 - lr: 1.0000e-04\n",
            "Epoch 48/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.2605 - val_accuracy: 0.9724 - lr: 1.0000e-04\n",
            "Epoch 49/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.2673 - val_accuracy: 0.9709 - lr: 1.0000e-05\n",
            "Epoch 50/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.2734 - val_accuracy: 0.9702 - lr: 1.0000e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(47024, 1)\n",
            "(47024,)\n",
            "(5878, 1)\n",
            "(5878,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid (5878, 64, 64)\n",
            "valid 5878\n",
            "train (47024, 64, 64)\n",
            "train 47024\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_18 (Conv1D)          (None, 64, 320)           246080    \n",
            "                                                                 \n",
            " conv1d_19 (Conv1D)          (None, 53, 320)           1229120   \n",
            "                                                                 \n",
            " max_pooling1d_9 (MaxPooling  (None, 26, 320)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 26, 320)           0         \n",
            "                                                                 \n",
            " bidirectional_9 (Bidirectio  (None, 64)               90368     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 16)                1040      \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,566,625\n",
            "Trainable params: 1,566,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 47024 samples, validate on 5878 samples\n",
            "Epoch 1/50\n",
            "47024/47024 [==============================] - ETA: 0s - loss: 0.3620 - accuracy: 0.8337"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47024/47024 [==============================] - 55s 1ms/sample - loss: 0.3620 - accuracy: 0.8337 - val_loss: 0.1555 - val_accuracy: 0.9570 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.2428 - accuracy: 0.8986 - val_loss: 0.1264 - val_accuracy: 0.9599 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.2016 - accuracy: 0.9188 - val_loss: 0.1071 - val_accuracy: 0.9631 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.1770 - accuracy: 0.9309 - val_loss: 0.1054 - val_accuracy: 0.9639 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.1587 - accuracy: 0.9400 - val_loss: 0.1111 - val_accuracy: 0.9602 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "47024/47024 [==============================] - 49s 1ms/sample - loss: 0.1459 - accuracy: 0.9437 - val_loss: 0.0947 - val_accuracy: 0.9668 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "47024/47024 [==============================] - 50s 1ms/sample - loss: 0.1386 - accuracy: 0.9479 - val_loss: 0.1089 - val_accuracy: 0.9626 - lr: 0.0010\n",
            "Epoch 8/50\n",
            " 7104/47024 [===>..........................] - ETA: 39s - loss: 0.1300 - accuracy: 0.9482"
          ]
        }
      ],
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "from tensorflow.keras import regularizers, Input, Model, Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "from tensorflow.keras.layers import Conv1D, Conv2D, BatchNormalization, MaxPool1D, MaxPool2D, Flatten, Dropout, Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "OutputDir = '/content/drive/MyDrive/Colab Notebooks/Research/Colab Notebooks/finals/results'\n",
        "\n",
        "trainning_result = []\n",
        "validation_result = []\n",
        "testing_result = []\n",
        "\n",
        "drop_out = 0.3\n",
        "LR= 0.001\n",
        "epochs = 50\n",
        "# batches = [512, 256, 200, 100]\n",
        "learning_rate = [0.001]\n",
        "dropout = [0.3]\n",
        "batches = [64]\n",
        "# lr = 0.02\n",
        "# dout = 0.2\n",
        "fils = 320\n",
        "ksize = 12\n",
        "acc = 0\n",
        "\n",
        "for test_index in range(folds):\n",
        "  valid_X = np.concatenate((Positive_X_Slices[test_index],Negative_X_Slices[test_index]))\n",
        "  valid_y = np.concatenate((Positive_y_Slices[test_index],Negative_y_Slices[test_index]))\n",
        "\n",
        "  validation_index = (test_index+1) % folds;\n",
        "\n",
        "  train_X = np.concatenate((Positive_X_Slices[validation_index],Negative_X_Slices[validation_index]))\n",
        "  train_y = np.concatenate((Positive_y_Slices[validation_index],Negative_y_Slices[validation_index]))\n",
        "\n",
        "  start = 0;\n",
        "\n",
        "  for val in range(0, folds):\n",
        "    if val != test_index and val != validation_index:\n",
        "      start = val;\n",
        "      break;\n",
        "\n",
        "  train_X = np.concatenate((Positive_X_Slices[start],Negative_X_Slices[start]))\n",
        "  train_y = np.concatenate((Positive_y_Slices[start],Negative_y_Slices[start]))\n",
        "\n",
        "  for i in range(0, folds):\n",
        "    if i != test_index and i != validation_index and i != start:\n",
        "      tempX = np.concatenate((Positive_X_Slices[i],Negative_X_Slices[i]))\n",
        "      tempy = np.concatenate((Positive_y_Slices[i],Negative_y_Slices[i]))\n",
        "\n",
        "      train_X = np.concatenate((train_X, tempX))\n",
        "      train_y = np.concatenate((train_y, tempy))\n",
        "\n",
        "  # test_X, test_y = shuffleData(test_X,test_y);\n",
        "  valid_X,valid_y = shuffleData(valid_X,valid_y);\n",
        "  train_X,train_y = shuffleData(train_X,train_y);\n",
        "\n",
        "\n",
        "  print(\"valid\", valid_X.shape)\n",
        "  print(\"valid\", len(valid_X))\n",
        "\n",
        "  print(\"train\", train_X.shape)\n",
        "  print(\"train\", len(train_X))\n",
        "\n",
        "  for batch in batches: \n",
        "    for lr in learning_rate:\n",
        "      for dout in dropout:\n",
        "        model = getModel(batch, lr, dout)\n",
        "\n",
        "        early_stopping = EarlyStopping(monitor='accuracy', patience= 20)\n",
        "        model_check = ModelCheckpoint(filepath = OutputDir + \"/the_model\"+ str(test_index+1) +\".h5\", monitor = 'accuracy', save_best_only=True)\n",
        "        reduct_L_rate = ReduceLROnPlateau(monitor='val_loss',factor=0.1, patience=20)\n",
        "\n",
        "        with tf.device('/device:GPU:0'):\n",
        "          history = model.fit(train_X, train_y, batch_size = batch, epochs = epochs, validation_data = (valid_X, valid_y), callbacks = [model_check, early_stopping,reduct_L_rate])\n",
        "\n",
        "        # bestModel =  load_model(OutputDir + \"/the_model.h5\")\n",
        "      # score = bestModel.evaluate(test_X, test_y, verbose=0)\n",
        "      # print(\"Accuracy: %.2f%%\" % (score[1]*100))\n",
        "\n",
        "      # print(calculateScore(train_X, train_y, bestModel))\n",
        "      # print(calculateScore(valid_X, valid_y, bestModel))\n",
        "      # print(calculateScore(test_X, test_y, bestModel))\n",
        "\n",
        "        trainning_result.append(calculateScore(train_X, train_y, model));\n",
        "        validation_result.append(calculateScore(valid_X, valid_y, model));\n",
        "      # testing_result.append(calculateScore(test_X, test_y, model));\n",
        "\n",
        "# temp_dict = (trainning_result, validation_result)\n",
        "# analyze(temp_dict, OutputDir);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhbPm81mMItd"
      },
      "outputs": [],
      "source": [
        "temp_dict = (trainning_result, validation_result)\n",
        "analyze(temp_dict, OutputDir);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ja_Y5sdNfwkV"
      },
      "outputs": [],
      "source": [
        "# import tensorflow.compat.v1 as tf\n",
        "# from tensorflow.keras import regularizers, Input, Model, Sequential\n",
        "# from tensorflow.keras.models import load_model\n",
        "\n",
        "# from tensorflow.keras.layers import Conv1D, Conv2D, BatchNormalization, MaxPool1D, MaxPool2D, Flatten, Dropout, Dense\n",
        "# from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "# tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "# OutputDir = '/content/drive/MyDrive/Colab Notebooks/Research/Colab Notebooks/other_simlar_res_net/results'\n",
        "\n",
        "# training_result = []\n",
        "# validation_result = []\n",
        "# testing_result = []\n",
        "\n",
        "# epochs = 50\n",
        "# batches = [512, 256, 200, 100]\n",
        "# learning_rate = [0.2,0.1, 0.02, 0.01]\n",
        "# dropout = [0.5, 0.4, 0.2]\n",
        "# fils = 320\n",
        "# ksize = 12\n",
        "# acc = 0\n",
        "\n",
        "# # model = getModel()\n",
        "# for batch in batches: \n",
        "#   for lr in learning_rate:\n",
        "#     for dout in dropout:\n",
        "#       model = getModel(batch, lr, dout)\n",
        "\n",
        "#       early_stopping = EarlyStopping(monitor='accuracy', patience=20)\n",
        "#       model_check = ModelCheckpoint(filepath = OutputDir + \"/model.h5\", monitor = 'accuracy', save_best_only=True)\n",
        "#       reduct_L_rate = ReduceLROnPlateau(monitor='val_loss',factor=0.1, patience=20)\n",
        "\n",
        "#       with tf.device('/device:GPU:0'):\n",
        "#         history = model.fit(train_X, train_y, batch_size = batch, epochs = epochs, validation_data = (valid_X, valid_y), callbacks = [model_check, early_stopping,reduct_L_rate])\n",
        "\n",
        "      # bestModel = load_model( OutputDir + \"/model.h5\")\n",
        "      # score = bestModel.evaluate(test_X, test_y, verbose=0)\n",
        "      # print(\"Accuracy: %.2f%%\" % (score[1]*100))\n",
        "\n",
        "      # training_result.append(calculateScore(train_X, train_y, model))\n",
        "      # validation_result.append(calculateScore(valid_X, valid_y, model))\n",
        "      # testing_result.append(calculateScore(test_X, test_y, model));\n",
        "\n",
        "      # temp_dict = (training_result, validation_result, testing_result)\n",
        "      # analyze(temp_dict, OutputDir);"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}